{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_sentences(data):\n",
    "    return sent_tokenize(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentence_to_POS(all_sentences):\n",
    "\n",
    "    data=[]\n",
    "    for sentence in all_sentences: \n",
    "        one_sentence_pos = []\n",
    "        '''\n",
    "        Word tokenizers is used to find the words and punctuation in a string \n",
    "        '''  \n",
    "        wordsList = nltk.word_tokenize(sentence) \n",
    "\n",
    "        '''\n",
    "        Removing stop words from wordList.\n",
    "        ''' \n",
    "        wordsList = [w for w in wordsList if not w in stop_words]  \n",
    "\n",
    "        '''\n",
    "        Using a Tagger. Which is part-of-speech tagger or POS-tagger.  \n",
    "        '''\n",
    "\n",
    "        tagged = nltk.pos_tag(wordsList) \n",
    "        for x in tagged:\n",
    "            one_sentence_pos.append(x[1])\n",
    "        data.append(one_sentence_pos)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "all_files = os.listdir('dataset/three_author_dataset')\n",
    "novel_POS=[]\n",
    "novel_label=[]\n",
    "for filename in all_files:\n",
    "    full_path = 'dataset/three_author_dataset/'+filename\n",
    "    with open(full_path, 'r') as f:\n",
    "        data = f.read().replace('\"\\n\"','').replace('\\n',' ').replace('- ','')\n",
    "        all_sentences = seperate_sentences(data)\n",
    "        sentences_to_pos = Sentence_to_POS(all_sentences)\n",
    "        novel_POS.append(sentences_to_pos)\n",
    "        novel_label.append(filename[8])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
